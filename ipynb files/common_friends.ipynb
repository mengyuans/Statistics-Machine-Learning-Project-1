{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import ast\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC, LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'/Users/dayijun/Desktop/Estelle computer/Textbook/UniMelb/COMP90051 - Statistical Machine Learning/AA')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test-public.txt\") as testFile:\n",
    "    rows = []\n",
    "    for t in testFile:\n",
    "        t = t.rstrip('\\n')\n",
    "        rows.append(t)\n",
    "        \n",
    "testId = list()\n",
    "source = list()\n",
    "sink = list()\n",
    "for i in rows:\n",
    "    separate = i.split(\"\\t\")\n",
    "    testId.append(separate[0])\n",
    "    source.append(separate[1])\n",
    "    sink.append(separate[2])\n",
    "testDf = pd.DataFrame({\"source\":source, \"sink\":sink}, index=testId)\n",
    "testDf = testDf.iloc[1:]\n",
    "testDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDf['source'] = testDf['source'].apply(int)\n",
    "testDf['sink'] = testDf['sink'].apply(int)\n",
    "dic=testDf.to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.getsizeof(dic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = testDf['sink'].to_list()\n",
    "a = set(a)\n",
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#source全都在那2万个ID里\n",
    "sourceInIndex = list()\n",
    "sourceNotInIndex = list()\n",
    "for i in testDf['source']:\n",
    "    if i in index:\n",
    "        sourceInIndex.append(i)\n",
    "    else:\n",
    "        sourceNotInIndex.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sourceNotInIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sinkInIndex = list()\n",
    "sinkNotInIndex = list()\n",
    "for i in testDf['sink']:\n",
    "    if i in index:\n",
    "        sinkInIndex.append(i)\n",
    "    else:\n",
    "        sinkNotInIndex.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sinkInIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sink里的人全都出现在follows里，其中376人在2万ID中,共出现11446次\n",
    "ss = list()\n",
    "#sinkNotInOthers = list()\n",
    "for i in followList:\n",
    "    for j in i:\n",
    "        if j in sinkNotInIndex:\n",
    "            ss.append(j)\n",
    "len(ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sinkInOthers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "te = set(sinkInOthers)\n",
    "len(te)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------分隔符-------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train.txt\") as trainFile:\n",
    "    lines = []\n",
    "    for line in trainFile:\n",
    "        line = line.rstrip('\\n')\n",
    "        lines.append(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = list()\n",
    "followList = list()\n",
    "for i in lines:\n",
    "    separate = i.split(\"\\t\")\n",
    "    index.append(separate[0])\n",
    "    followList.append(separate[1:])\n",
    "df = pd.DataFrame({\"follow\":followList}, index=index)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDic = df.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.getsizeof(dfDic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in df.loc['585576']:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inIndex = list()\n",
    "for i in df['follow']:\n",
    "    for j in i:\n",
    "        if j in df.index:\n",
    "            inIndex.append(j)\n",
    "len(inIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notInIndex = list()\n",
    "inIndex = list()\n",
    "for i in df['follow']:\n",
    "    for j in i:\n",
    "        if j not in df.index:\n",
    "            notInIndex.append(j)\n",
    "        else:\n",
    "            inIndex.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notInIndex = set(notInIndex)\n",
    "inIndex = set(inIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inIndex = list()\n",
    "len(notInIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(inIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notInIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.index[0]\n",
    "#df.loc[ '540762' , : ]\n",
    "#a = df.loc['540762', : ]\n",
    "#for i in a:\n",
    "#    for j in i:\n",
    "#        print(j)\n",
    "#type(sourceNeighbour)\n",
    "sourceNeighbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#不管方向\n",
    "scoreList = list()\n",
    "\n",
    "for i in range(2000):\n",
    "    source = testDf.source[i]\n",
    "    [sourceNeighbour] = df.loc[source, : ].tolist()\n",
    "    for j in range(100):\n",
    "        for k in df.follow[j]:\n",
    "            if source in k:\n",
    "                sourceNeighbour.append(df.index[j])\n",
    "    #sourceNeighbour = list(set(sourceNeighbour))\n",
    "\n",
    "    sink = testDf.sink[i]\n",
    "    sinkNeighbour = list()\n",
    "    if sink in df.index:\n",
    "        [sinkNeighbour] = df.loc[sink, : ].tolist()\n",
    "    for j in range(100):\n",
    "        for k in df.follow[j]:\n",
    "            if sink in k:\n",
    "                sinkNeighbour.append(df.index[j])\n",
    "    #sinkNeighbour = list(set(sinkNeighbour))\n",
    "\n",
    "    total = len(sinkNeighbour) + len(sourceNeighbour)\n",
    "    allList = sinkNeighbour + sourceNeighbour\n",
    "    allList = set(allList)\n",
    "    different = len(allList) - (total - len(allList))\n",
    "\n",
    "    common = 0\n",
    "    for m in sourceNeighbour:\n",
    "        if m in sinkNeighbour:\n",
    "            common += 1\n",
    "\n",
    "    score = common/different\n",
    "    scoreList.append(score)\n",
    "    \n",
    "\n",
    "scoreList  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(scoreList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = '540762'\n",
    "for j in range(20000):\n",
    "    for k in df.follow[j]:\n",
    "        if index in k:\n",
    "            print(df.index[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ['fe']\n",
    "b = ['dd']\n",
    "a = a+b\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"train_mini_graph.txt\", \"r\")\n",
    "\n",
    "contents = file.read()\n",
    "train_mini_graph = ast.literal_eval(contents)\n",
    "# train_mini_graph will be the dictionary that represents the graph\n",
    "file.close()\n",
    "\n",
    "test_mini = pd.read_csv(\"test_mini.csv\")\n",
    "test_mini_source = test_mini.test_source.values.tolist()\n",
    "test_mini_sink = test_mini.test_sink.values.tolist()\n",
    "for i in range(len(test_mini_source)):\n",
    "    test_mini_source[i] = str(test_mini_source[i])\n",
    "for i in range(len(test_mini_sink)):\n",
    "    test_mini_sink[i] = str(test_mini_sink[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#代替之前 train.txt 2万个的\n",
    "file = open(\"train_modified.txt\", \"r\")\n",
    "\n",
    "contents = file.read()\n",
    "train_modified_graph = ast.literal_eval(contents)\n",
    "file.close()\n",
    "\n",
    "#代替之前2000个test的\n",
    "train_modify = pd.read_csv(\"train_set.csv\")\n",
    "train_modify_source = train_modify.train_source.values.tolist()\n",
    "train_modify_sink = train_modify.train_sink.values.tolist()\n",
    "for i in range(len(train_modify_source)):\n",
    "    train_modify_source[i] = str(train_modify_source[i])\n",
    "for i in range(len(train_modify_sink)):\n",
    "    train_modify_sink[i] = str(train_modify_sink[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_modify_label = train_modify.label.values.tolist()\n",
    "train_modify_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_modify_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#新的train的\n",
    "scoreList = list()\n",
    "\n",
    "for i in tqdm(range(19350)):\n",
    "    source = train_modify_source[i]\n",
    "    sourceNeighbour = train_modified_graph[source]\n",
    "    for key in train_modified_graph.keys():\n",
    "        if source in train_modified_graph[key]:\n",
    "            sourceNeighbour.append(key)\n",
    "\n",
    "\n",
    "    sink = train_modify_sink[i]\n",
    "    sinkNeighbour = list()\n",
    "    \n",
    "    if sink in train_modified_graph.keys():\n",
    "        sinkNeighbour = train_modified_graph[sink]\n",
    "    \n",
    "    for key in train_modified_graph:\n",
    "        if sink in train_modified_graph[key]:\n",
    "            sinkNeighbour.append(key)\n",
    "\n",
    "    allList = set(sinkNeighbour + sourceNeighbour)\n",
    "    different = len(allList)\n",
    "    \n",
    "    common = 0\n",
    "    for m in sourceNeighbour:\n",
    "        if m in sinkNeighbour:\n",
    "            common += 1\n",
    "            \n",
    "    score = common/different\n",
    "    scoreList.append(score)\n",
    "    \n",
    "\n",
    "scoreList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scoreList = list()\n",
    "\n",
    "for i in range(2000):\n",
    "    source = test_source[i]\n",
    "    source = test_source[i]\n",
    "    sourceNeighbour = train[source]\n",
    "    for key in train.keys():\n",
    "        if source in train[key]:\n",
    "            sourceNeighbour.append(key)\n",
    "\n",
    "\n",
    "    #sourceNeighbour = list(set(sourceNeighbour))\n",
    "\n",
    "    sink = test_sink[i]\n",
    "    sinkNeighbour = list()\n",
    "    \n",
    "    if sink in train.keys():\n",
    "        sinkNeighbour = train[sink]\n",
    "    \n",
    "    for key in train:\n",
    "        if sink in train[key]:\n",
    "            sinkNeighbour.append(key)\n",
    "    #sinkNeighbour = list(set(sinkNeighbour))\n",
    "\n",
    "    \n",
    "    allList = set(sinkNeighbour + sourceNeighbour)\n",
    "    different = len(allList)\n",
    "    \n",
    "    \n",
    "    common = 0\n",
    "    for m in sourceNeighbour:\n",
    "        if m in sinkNeighbour:\n",
    "            common += 1\n",
    "            \n",
    "    score = common/different\n",
    "    scoreList.append(score)\n",
    "    \n",
    "\n",
    "scoreList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = {}\n",
    "with open('train.txt') as f: \n",
    "    for line in f:\n",
    "        words = line.split(\"\\t\")\n",
    "        words[-1] = words[-1][:-1]\n",
    "        train[words[0]] = words[1:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_source = []\n",
    "test_sink = []\n",
    "with open('test-public.txt') as f: \n",
    "    for line in f:\n",
    "        words = line.split(\"\\t\")\n",
    "        test_source.append(words[1])\n",
    "        test_sink.append(words[2][:-1])\n",
    "    test_source = test_source[1:]\n",
    "    test_sink= test_sink[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.getsizeof(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#之前2001\n",
    "predictedId = range(1, 19351)\n",
    "predictedDf = pd.DataFrame({\"Id\":predictedId, \"Predicted\":scoreList})\n",
    "predictedDf = pd.DataFrame(predictedDf,columns = ['Id','Predicted'])\n",
    "predictedDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in scoreList:\n",
    "    if i > 0:\n",
    "        count += 1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictedDf.to_csv('/Users/dayijun/Desktop/Estelle computer/Textbook/UniMelb/COMP90051 - Statistical Machine Learning/AA/predictedTrainedCommonFriends.csv',index=False)\n",
    "#np.savetxt(r'/Users/dayijun/Desktop/Estelle computer/Textbook/UniMelb/COMP90051 - Statistical Machine Learning/AA/predicted.txt', predictedDf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distanceList = list()\n",
    "\n",
    "for i in tqdm(range(2000)):\n",
    "    source = test_source[i]\n",
    "    sink = test_sink[i]\n",
    "    source_followees = train[source]\n",
    "    \n",
    "    distance = 0\n",
    "  \n",
    "    count2 = 0\n",
    "    #second_level_followees = list()\n",
    "    all_second_followees = list()\n",
    "    for j in source_followees:\n",
    "        if j in train.keys():\n",
    "            all_second_followees = all_second_followees + train[j]\n",
    "            if sink in train[j]:\n",
    "                count2 += 1\n",
    "                \n",
    "                    \n",
    "    all_second_followees = set(all_second_followees)\n",
    "    se_followees_no = len(all_second_followees)\n",
    "    \n",
    "    count3 = 0 \n",
    "    all_thi_followees = list()\n",
    "    for k in all_second_followees:\n",
    "        if k in train.keys():\n",
    "            all_thi_followees = all_thi_followees + train[k]\n",
    "            if sink in train[k]:\n",
    "                count3 += 1\n",
    "                \n",
    "    all_thi_followees = set(all_thi_followees)\n",
    "    thi_followees_no = len(all_thi_followees)\n",
    "    \n",
    "    \n",
    "    count4 = 0\n",
    "    all_fo_followees = list()\n",
    "    for l in all_thi_followees:\n",
    "        if l in train.keys():\n",
    "            all_fo_followees = all_fo_followees + train[l]\n",
    "            if sink in train[l]:\n",
    "                count4 += 1\n",
    "    all_fo_followees = set(all_fo_followees)\n",
    "    fo_followees_no = len(all_fo_followees)\n",
    "    \n",
    "    \n",
    "    count5 = 0\n",
    "    all_fif_followees = list()\n",
    "    for m in all_fo_followees:\n",
    "        if m in train.keys():\n",
    "            all_fo_followees = all_fo_followees + train[m]\n",
    "            if sink in train[m]:\n",
    "                count5 += 1\n",
    "    all_fif_followees = set(all_fif_followees)\n",
    "    fif_followees_no = len(all_fif_followees)\n",
    "\n",
    "    total = count2 + count3 + count4 + count5\n",
    "    \n",
    "    pro2 = pro3 = pro4 = pro5 =0\n",
    "    if se_followees_no!= 0:\n",
    "        pro2 = count2/se_followees_no\n",
    "    if thi_followees_no != 0:\n",
    "        pro3 = count3/thi_followees_no\n",
    "    if fo_followees_no != 0:\n",
    "        pro4 = count4/fo_followees_no\n",
    "    if fif_followees_no != 0:\n",
    "        pro5 = count5/fif_followees_no\n",
    "    \n",
    "    if total != 0:\n",
    "        distance = pro2*count2/total*1/2+pro3*count3/total*1/3+pro4*count4/total*1/4+pro5*count5/total*1/5\n",
    "    \n",
    "    distanceList.append(distance)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(predictedDf.Id[0:9674], common_interest[0:9674],  color='b', label=\"$y = 0$\")\n",
    "plt.scatter(predictedDf.Id[9675:], common_interest[9675:],   color='r', label=\"$y = 1$\")\n",
    "\n",
    "#train_modify_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(predictedDf.Id[0:9674], predictedDf.Predicted[0:9674],  color='b', label=\"$y = 0$\")\n",
    "plt.scatter(predictedDf.Id[9675:], predictedDf.Predicted[9675:],   color='r', label=\"$y = 1$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset_common_interest = pd.read_csv(\"trainset_common_interest2.csv\")\n",
    "common_interest = trainset_common_interest.common_interest.values.tolist()\n",
    "\n",
    "common_interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelDf = pd.DataFrame({\"Label\": train_modify_label, \"CommonInterest\":common_interest, \"CommonFriends\":scoreList})\n",
    "modelDf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(modelDf, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(train_df[[col for col in modelDf.columns if col != 'Label']]) # fill in\n",
    "y_train = train_df.Label # fill in\n",
    "\n",
    "X_test = scaler.fit_transform(test_df[[col for col in modelDf.columns if col != 'Label']]) # fill in\n",
    "y_test = test_df.Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_train[y_train==1,0], X_train[y_train==1,1], label=\"True ($y=1$)\", c='r')\n",
    "plt.scatter(X_train[y_train==0,0], X_train[y_train==0,1], label=\"False ($y=0$)\", c='b')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_range = np.logspace(-2, 5, 8)\n",
    "gamma_range = np.logspace(-6, 1, 16)\n",
    "\n",
    "# Visualise the grid\n",
    "xx, yy = np.meshgrid(C_range, gamma_range)\n",
    "plt.plot(xx, yy, 'ko')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('$C$')\n",
    "plt.ylabel(r'$\\gamma$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedShuffleSplit(n_splits=30, test_size=0.1, random_state=1)\n",
    "grid = GridSearchCV(SVC(kernel='rbf'), param_grid={'gamma': gamma_range, 'C': C_range}, cv=cv)\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"The best parameters are {0.best_params_} with an accuracy of {0.best_score_:.3g}\".format(grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
