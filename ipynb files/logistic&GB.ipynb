{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model = pd.read_csv('rank_train_set.csv')\n",
    "train_model.set_index('Id')\n",
    "train_f5 = pd.DataFrame(train_model[['common_interest', 'common_friends', 'distance','source_degree','sink_degree','label']])\n",
    "X = np.array(train_f5[['common_interest', 'common_friends', 'distance','source_degree','sink_degree']])\n",
    "y = np.array(train_f5.label)\n",
    "print(X, y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression validation with l2 regularization\n",
    "clf = LogisticRegression(penalty='l2')\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print('validation accuracy is', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test file \n",
    "df = pd.read_csv('rank_test_public.csv')\n",
    "test = df[['common_interest', 'common_friends', 'distance','source_degree','sink_degree']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict logistic regression+regularization probability on 2000 test set\n",
    "prob = list(clf.predict_proba(test))\n",
    "\n",
    "# find the number of positive edges\n",
    "n_logistic = 0 #1027\n",
    "for i in clf.predict_proba(test)[:,1]:\n",
    "    if i >= 0.5:\n",
    "        n_logistic+=1\n",
    "\n",
    "print(n_logistic, 'out of 2000 are classified as label 1')\n",
    "\n",
    "# extract label 1 probabilities\n",
    "l_lr = []\n",
    "for i in prob:\n",
    "    l_lr.append(i[1])\n",
    "index = list(range(1,2001))\n",
    "data = {'Id':index, 'Predicted':l_lr}\n",
    "logistic_try_v1 = pd.DataFrame(data)\n",
    "logistic_try_v1 = logistic_try_v1.set_index('Id')\n",
    "logistic_try_v1.to_csv('logistic_try_v1.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting classifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "GB = GradientBoostingClassifier(random_state=10)\n",
    "GB.fit(X_train, y_train)\n",
    "y_pred_GB = GB.predict(X_test)\n",
    "\n",
    "print('validation accuracy is', accuracy_score(y_test, y_pred_GB))\n",
    "\n",
    "prob_GB = list(GB.predict_proba(test))\n",
    "n_GB = 0 #1077\n",
    "for i in GB.predict_proba(test)[:,1]:\n",
    "    if i >= 0.5:\n",
    "        n_GB+=1\n",
    "print(n_GB, 'of 2000 are classified as label 1')\n",
    "\n",
    "l_GB = []\n",
    "for i in prob_GB:\n",
    "    l_GB.append(i[1])\n",
    "index = list(range(1,2001))\n",
    "data_GB = {'Id':index, 'Predicted':l_GB}\n",
    "GB_v1 = pd.DataFrame(data_GB)\n",
    "GB_v1 = GB_v1.set_index('Id')\n",
    "#GB_v1.to_csv('GB_v1.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuning GB parameters\n",
    "from sklearn.model_selection import GridSearchCV #Performing grid search\n",
    "\n",
    "predictors = X\n",
    "param_test1 = {'n_estimators':range(10,81,10)}\n",
    "gsearch1 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1, min_samples_split=150,min_samples_leaf=50,max_depth=5,max_features='sqrt',random_state=10), \n",
    "param_grid = param_test1, scoring='roc_auc',n_jobs=4,iid=False, cv=10, refit=True)\n",
    "predictors = ['common_interest', 'common_friends', 'distance','source_degree','sink_degree']\n",
    "target = ['label']\n",
    "gsearch1.fit(train_f5[predictors],train_f5[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mini_samples_split normally is 0.5-1% of total values\n",
    "param_test2 = {'max_depth':range(1,6,1), 'min_samples_split':range(20,251,20)}\n",
    "gsearch2 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1, n_estimators=40, max_features='sqrt', random_state=10), \n",
    "param_grid = param_test2, scoring='roc_auc',n_jobs=4,iid=False, cv=10, refit=True)\n",
    "gsearch2.fit(train_f5[predictors],train_f5[target])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch2.best_params_, gsearch2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test3 = {'min_samples_split':range(20,251,20), 'min_samples_leaf':range(1,71,10)}\n",
    "gsearch3 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1, n_estimators=40,max_depth=5,max_features='sqrt', subsample=0.8, random_state=10), \n",
    "param_grid = param_test3, scoring='roc_auc',n_jobs=4,iid=False, cv=10)\n",
    "gsearch3.fit(train_f5[predictors],train_f5[target])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch3.best_params_, gsearch3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GB_tune = gsearch3.best_estimator_\n",
    "GB_tune.fit(X_train, y_train)\n",
    "y_pred_GB_tune = GB_tune.predict(X_test)\n",
    "print('validation accuracy is', roc_auc_score(y_test, y_pred_GB_tune))\n",
    "\n",
    "prob_GB_tune = list(GB_tune.predict_proba(test))\n",
    "n_GB_tune = 0 #1032\n",
    "for i in GB_tune.predict_proba(test)[:,1]:\n",
    "    if i >= 0.5:\n",
    "        n_GB_tune += 1\n",
    "        \n",
    "print(n_GB_tune, 'of 2000 are classified as label 1')\n",
    "\n",
    "l_GB_tune = []\n",
    "for i in prob_GB_tune:\n",
    "    l_GB_tune.append(i[1])\n",
    "index = list(range(1,2001))\n",
    "data_GB_tune = {'Id':index, 'Predicted':l_GB_tune}\n",
    "GB_v1 = pd.DataFrame(data_GB_tune)\n",
    "GB_v1 = GB_v1.set_index('Id')\n",
    "#GB_v1.to_csv('GB_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test4 = {'max_features':range(1,6,2)}\n",
    "gsearch4 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1, n_estimators=40,max_depth=5, min_samples_split=20, min_samples_leaf=1, random_state=10),\n",
    "param_grid = param_test4, scoring='roc_auc',n_jobs=4,iid=False, cv=10)\n",
    "gsearch4.fit(train_f5[predictors],train_f5[target])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch4.best_params_, gsearch4.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### try this GB ####################\n",
    "gbm_tuned_1 = GradientBoostingClassifier(learning_rate=0.1, n_estimators=40,max_depth=5, min_samples_split=140,min_samples_leaf=1, random_state=10, max_features=5)\n",
    "gbm_tuned_1.fit(X_train, y_train)\n",
    "y_pred_GB_1 = gbm_tuned_1.predict(X_test)\n",
    "\n",
    "print('validation accuracy is', roc_auc_score(y_test, y_pred_GB_1))\n",
    "\n",
    "prob_gbm_1 = list(gbm_tuned_1.predict_proba(test))\n",
    "n_gbm_1 = 0 #1055\n",
    "for i in gbm_tuned_1.predict_proba(test)[:,1]:\n",
    "    if i >= 0.5:\n",
    "        n_gbm_1+=1\n",
    "print(n_gbm_1, 'of 2000 are classified as label 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
